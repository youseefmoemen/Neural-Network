{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/youseefmoemen/Neural-Network/blob/main/Sup2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GON6iRSbG-PX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tv84SdZlPrxd"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "  return 1 / (1 + np.exp(-1 * z))\n",
    "def sigmoid_grad(z):\n",
    "  t = sigmoid(z)\n",
    "  return t * (1 - t)\n",
    "def leakyRelu(z):\n",
    "  return np.where(z >= 0, z, z * 0.3)\n",
    "def leakyRelu_grad(z):\n",
    "  return np.where(z >= 0, 1, 0.3)\n",
    "def tanh(z):\n",
    "  return np.tanh(z)\n",
    "def tanh_grad(z):\n",
    "  return 1 - np.power(tanh(z), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "A8eh2OJgP7IB"
   },
   "outputs": [],
   "source": [
    "Activations = {\n",
    "    'sigmoid': sigmoid,\n",
    "    'leakyRelu': leakyRelu,\n",
    "    'tanh': tanh\n",
    "}\n",
    "Activations_grad = {\n",
    "    'sigmoid': sigmoid_grad,\n",
    "    'leakyRelu': leakyRelu_grad,\n",
    "    'tanh': tanh_grad\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "15j6dXKLIWN_"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1Vx8P1VUHdk0"
   },
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KVLMhO_MIYzq"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mXY0wY3DIbFX"
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits = 1, train_size=50000, test_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "D1VbSFuaIcp5"
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in sss.split(mnist.data, mnist.target):\n",
    "  X_train = mnist.data.iloc[train_index] \n",
    "  y_train = mnist.target[train_index]\n",
    "  X_test = mnist.data.iloc[test_index] \n",
    "  y_test = mnist.target[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CKFS19L0Ierk"
   },
   "outputs": [],
   "source": [
    "def clip_image(img, clipping_size = 0):\n",
    "  img = img.reshape((28, 28))\n",
    "  img = np.delete(img, range(clipping_size), 0)\n",
    "  img = np.delete(img, range(clipping_size), 1)\n",
    "  return img.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "75II8JDuIhF3"
   },
   "outputs": [],
   "source": [
    "def momentum(img, step_size, n_steps, clipping_size):\n",
    "  img = img.reshape((28 - clipping_size, 28-clipping_size))\n",
    "  momentums = []\n",
    "  for i in range(n_steps):\n",
    "    x = np.array(list(range(i*step_size, (i+1)*step_size)))\n",
    "    for j in range(n_steps):\n",
    "      pixels = img[j*step_size: (j+1)*step_size, i*step_size: (i+1) * step_size]\n",
    "      y =  np.array(list(range(j*step_size, (j+1)*step_size))).reshape(step_size,1)\n",
    "      area = np.sum(np.sum(pixels))\n",
    "      x_c = np.sum(np.sum(x.T * pixels)) / (area + 1e-10)\n",
    "      y_c = np.sum(np.sum(y * pixels)) / (area + 1e-10)\n",
    "      momentums.append((x_c, y_c))\n",
    "  return momentums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_hZcCsCXIimx"
   },
   "outputs": [],
   "source": [
    "def reduction(data = None, n_momentums = 9):\n",
    "  n_steps = math.floor(np.sqrt(n_momentums))\n",
    "  clipping_size = 28 % n_steps\n",
    "  step_size = (28 - clipping_size) // n_steps\n",
    "  data = np.apply_along_axis(clipping_size = clipping_size\n",
    "                      , func1d = clip_image, axis = 1, arr = data)\n",
    "  momentums = np.apply_along_axis(step_size = step_size, n_steps = n_steps,\n",
    "                                  clipping_size= clipping_size,\n",
    "                                  func1d = momentum, axis = 1, arr = data)\n",
    "  return data, momentums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XeGU_ZnMIkCS"
   },
   "outputs": [],
   "source": [
    "X_train = reduction(np.array(X_train.copy()), n_momentums = 9)[1].reshape(50000, 18)\n",
    "y_train2 = np.zeros(shape=(y_train.shape[0], 10))\n",
    "for index, instance in enumerate(y_train):\n",
    "  y_train2[index][int(instance)] = 1\n",
    "y_train = y_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = reduction(np.array(X_test.copy()), n_momentums = 9)[1].reshape(10000, 18)\n",
    "y_test2 = np.zeros(shape=(y_test.shape[0], 10))\n",
    "for index, instance in enumerate(y_test):\n",
    "  y_test2[index][int(instance)] = 1\n",
    "y_test = y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JDuzFFNDBMWj"
   },
   "outputs": [],
   "source": [
    "class Layer():\n",
    "  def __init__(self, n_neurons, activation):\n",
    "    self.n_neurons = n_neurons\n",
    "    self.w = None\n",
    "    self.activation = Activations[activation]\n",
    "    self.activation_grad = Activations_grad[activation]\n",
    "  \n",
    "  def initialize(self, prev):\n",
    "    self.w = np.random.normal(size=(self.n_neurons, prev))\n",
    "\n",
    "  def compute(self, Oi):\n",
    "    Netj = np.dot(Oi, self.w.T)  \n",
    "    Oj = self.activation(Netj)\n",
    "    return Netj, Oj\n",
    "  \n",
    "  def grad(self, delta, w_next, Oi):\n",
    "    Netj = self.compute(Oi)[0]\n",
    "    partial = np.dot(delta, w_next)\n",
    "    delta = np.multiply(partial, self.activation_grad(Netj))\n",
    "    Dw = np.dot(delta.T, Oi)\n",
    "    return Dw, delta\n",
    "\n",
    "  def update(self, learning_rate, Dw):\n",
    "    hold = self.w.shape\n",
    "    self.w  = self.w  -  learning_rate * Dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OMW5bsyJUuDX"
   },
   "outputs": [],
   "source": [
    "class OutputLayer(Layer):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "  \n",
    "  def grad(self, target, Oi):\n",
    "    Netj, Oj = self.compute(Oi)\n",
    "    delta = np.multiply(-1* (1/target.shape[0]) * (target - Oj), self.activation_grad(Netj))\n",
    "    Dw = np.dot(delta.T, Oi)\n",
    "    return Dw, delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-v5Lkksr4xb5"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "  def __init__(self, layers, input_shape, losses, accuracies):\n",
    "    self.layers = layers\n",
    "    self.O_ALL = None\n",
    "    self.input_shape = input_shape\n",
    "    self.losses = losses\n",
    "    self.accuracies = accuracies\n",
    "    self.layers[0].initialize(self.input_shape)\n",
    "    for i in range(1, len(self.layers)):\n",
    "      self.layers[i].initialize(self.layers[i-1].n_neurons)\n",
    "  \n",
    "  def predict(self, X):\n",
    "    Oi = X\n",
    "    self.O_ALL = []\n",
    "    self.O_ALL.append(X)\n",
    "    for layer in self.layers:\n",
    "      Oi = layer.compute(Oi)[1]\n",
    "      self.O_ALL.append(Oi)\n",
    "    return Oi\n",
    "  \n",
    "\n",
    "  def loss(self, Oj, y):\n",
    "    E = (2 / y.shape[0]) * np.sum((y - Oj) ** 2)\n",
    "    return E\n",
    "  \n",
    "\n",
    "  def argmax(self, y):\n",
    "      MIN_INT = -sys.maxsize - 1\n",
    "      output = []\n",
    "      for yhat in y:\n",
    "          max = MIN_INT\n",
    "          max_idx = -1\n",
    "          for i, val in enumerate(yhat):\n",
    "              if val > max:\n",
    "                  max = val\n",
    "                  max_idx = i\n",
    "          output.append(max_idx)\n",
    "      return output\n",
    "\n",
    "  def accuracy(self, y_pred, y_true):\n",
    "    return np.sum(np.equal(self.argmax(y_true), self.argmax(y_pred))) / len(y_true)\n",
    "\n",
    "  def train(self, X_train, y_train, learning_rate, epochs, \n",
    "            X_val = None, y_val = None):\n",
    "    for i in range(epochs):\n",
    "        y_pred = self.predict(X_train)\n",
    "        print(f'epoch {i} accuracy {self.accuracy(y_pred, y_train)}' ,\n",
    "              f'loss {self.loss(y_train, y_pred)}')\n",
    "        losses.append(self.loss(y_train, y_pred))\n",
    "        accuracies.append(self.accuracy(y_pred, y_train))\n",
    "        for index, instance in enumerate(X_train):\n",
    "          self.predict(instance.reshape(1, -1))\n",
    "          for j in reversed(range(len(self.layers))):\n",
    "            if j == len(self.layers) - 1:\n",
    "              Dw, delta = self.layers[j].grad(y_train[index], self.O_ALL[-2])\n",
    "            else:\n",
    "              Dw, delta = self.layers[j].grad(delta, hold, self.O_ALL[j])\n",
    "            hold = self.layers[j].w.copy()\n",
    "            self.layers[j].update(learning_rate, Dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5-C_1w4BpiK",
    "outputId": "17e53297-9ebc-456a-bd73-8f4c9a39d8bf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy 0.09018 loss 5.685311882205546\n",
      "epoch 1 accuracy 0.28132 loss 1.6609565023869184\n",
      "epoch 2 accuracy 0.30222 loss 1.603179559044652\n",
      "epoch 3 accuracy 0.31354 loss 1.5621453175158462\n",
      "epoch 4 accuracy 0.32356 loss 1.5326161789358665\n",
      "epoch 5 accuracy 0.33196 loss 1.5126869571474624\n",
      "epoch 6 accuracy 0.35374 loss 1.502117408753107\n",
      "epoch 7 accuracy 0.3578 loss 1.4960741369118427\n",
      "epoch 8 accuracy 0.3761 loss 1.4814574113371435\n",
      "epoch 9 accuracy 0.38322 loss 1.464195569773988\n",
      "epoch 10 accuracy 0.4024 loss 1.4500648322311551\n",
      "epoch 11 accuracy 0.40908 loss 1.444565262136777\n",
      "epoch 12 accuracy 0.43542 loss 1.4031382165049162\n",
      "epoch 13 accuracy 0.43932 loss 1.3871971954723579\n",
      "epoch 14 accuracy 0.43982 loss 1.3732788778041654\n",
      "epoch 15 accuracy 0.43852 loss 1.362237229406456\n",
      "epoch 16 accuracy 0.44134 loss 1.346324565785066\n",
      "epoch 17 accuracy 0.44708 loss 1.3350980208874987\n",
      "epoch 18 accuracy 0.45338 loss 1.3237167964095071\n",
      "epoch 19 accuracy 0.45752 loss 1.3174283195797747\n",
      "epoch 20 accuracy 0.45984 loss 1.3117767505315623\n",
      "epoch 21 accuracy 0.46426 loss 1.3038274582009295\n",
      "epoch 22 accuracy 0.46644 loss 1.2999083552419788\n",
      "epoch 23 accuracy 0.47488 loss 1.2952890419953622\n",
      "epoch 24 accuracy 0.47746 loss 1.290903701786739\n",
      "epoch 25 accuracy 0.47986 loss 1.2856920264775444\n",
      "epoch 26 accuracy 0.47616 loss 1.2908035689085153\n",
      "epoch 27 accuracy 0.475 loss 1.2917447974160916\n",
      "epoch 28 accuracy 0.48266 loss 1.2774135061177359\n",
      "epoch 29 accuracy 0.4831 loss 1.2750769609669859\n",
      "epoch 30 accuracy 0.48356 loss 1.2735629382291835\n",
      "epoch 31 accuracy 0.48448 loss 1.2736493612009958\n",
      "epoch 32 accuracy 0.48472 loss 1.2737146684313965\n",
      "epoch 33 accuracy 0.48668 loss 1.272792276790947\n",
      "epoch 34 accuracy 0.48386 loss 1.2811948277409577\n",
      "epoch 35 accuracy 0.48774 loss 1.27089307190095\n",
      "epoch 36 accuracy 0.4894 loss 1.2635485702567302\n",
      "epoch 37 accuracy 0.4896 loss 1.2630163196581097\n",
      "epoch 38 accuracy 0.491 loss 1.2625857308240647\n",
      "epoch 39 accuracy 0.49264 loss 1.2585939657414318\n",
      "epoch 40 accuracy 0.49256 loss 1.2580101215781634\n",
      "epoch 41 accuracy 0.49362 loss 1.2588123713131099\n",
      "epoch 42 accuracy 0.49568 loss 1.2505661028954025\n",
      "epoch 43 accuracy 0.496 loss 1.2494234958540953\n",
      "epoch 44 accuracy 0.49974 loss 1.2421826780271341\n",
      "epoch 45 accuracy 0.50274 loss 1.2380612872394101\n",
      "epoch 46 accuracy 0.5018 loss 1.2346826288395394\n",
      "epoch 47 accuracy 0.50418 loss 1.2299587502955893\n",
      "epoch 48 accuracy 0.50734 loss 1.2278322372216857\n",
      "epoch 49 accuracy 0.50842 loss 1.226389921068227\n",
      "epoch 50 accuracy 0.50852 loss 1.2285436568509658\n",
      "epoch 51 accuracy 0.50926 loss 1.2240335623518208\n",
      "epoch 52 accuracy 0.50858 loss 1.2244636843414043\n",
      "epoch 53 accuracy 0.51154 loss 1.2203971629829928\n",
      "epoch 54 accuracy 0.51342 loss 1.216462276525486\n",
      "epoch 55 accuracy 0.52482 loss 1.2103309486039526\n",
      "epoch 56 accuracy 0.52682 loss 1.2037247454904851\n",
      "epoch 57 accuracy 0.53194 loss 1.194573408693578\n",
      "epoch 58 accuracy 0.53678 loss 1.1918558009424267\n",
      "epoch 59 accuracy 0.53794 loss 1.189304468220003\n",
      "epoch 60 accuracy 0.53948 loss 1.1842515014197443\n",
      "epoch 61 accuracy 0.5416 loss 1.1865430502273744\n",
      "epoch 62 accuracy 0.54186 loss 1.18435303743357\n",
      "epoch 63 accuracy 0.54266 loss 1.1822435493931325\n",
      "epoch 64 accuracy 0.54358 loss 1.1778603398939118\n",
      "epoch 65 accuracy 0.54712 loss 1.175691408346094\n",
      "epoch 66 accuracy 0.5474 loss 1.1718061141170049\n",
      "epoch 67 accuracy 0.54722 loss 1.1705931906208802\n",
      "epoch 68 accuracy 0.54766 loss 1.1696439934712015\n",
      "epoch 69 accuracy 0.54696 loss 1.172595640387768\n",
      "epoch 70 accuracy 0.54762 loss 1.1714901551591246\n",
      "epoch 71 accuracy 0.54822 loss 1.1677019802840936\n",
      "epoch 72 accuracy 0.54906 loss 1.1682761258915482\n",
      "epoch 73 accuracy 0.54638 loss 1.1696178713237386\n",
      "epoch 74 accuracy 0.54896 loss 1.1656802783500082\n",
      "epoch 75 accuracy 0.54596 loss 1.1680448594049775\n",
      "epoch 76 accuracy 0.54854 loss 1.166846336197836\n",
      "epoch 77 accuracy 0.54878 loss 1.164968605309207\n",
      "epoch 78 accuracy 0.5491 loss 1.1664449458573494\n",
      "epoch 79 accuracy 0.54928 loss 1.165304458372233\n",
      "epoch 80 accuracy 0.5492 loss 1.1634568108305308\n",
      "epoch 81 accuracy 0.5496 loss 1.1641953717148825\n",
      "epoch 82 accuracy 0.54872 loss 1.1640324000501403\n",
      "epoch 83 accuracy 0.54958 loss 1.1647526168249673\n",
      "epoch 84 accuracy 0.54946 loss 1.160840987810354\n",
      "epoch 85 accuracy 0.54988 loss 1.1588793163283002\n",
      "epoch 86 accuracy 0.55032 loss 1.157023225937142\n",
      "epoch 87 accuracy 0.54988 loss 1.1571508489840734\n",
      "epoch 88 accuracy 0.54988 loss 1.1546935013427095\n",
      "epoch 89 accuracy 0.54796 loss 1.1563915159725435\n",
      "epoch 90 accuracy 0.54956 loss 1.1532045058974745\n",
      "epoch 91 accuracy 0.55016 loss 1.1517038845631202\n",
      "epoch 92 accuracy 0.55028 loss 1.1507000606225737\n",
      "epoch 93 accuracy 0.5509 loss 1.1494498998557228\n",
      "epoch 94 accuracy 0.54096 loss 1.166140526176312\n",
      "epoch 95 accuracy 0.54058 loss 1.16309275755258\n",
      "epoch 96 accuracy 0.54752 loss 1.1621313347434457\n",
      "epoch 97 accuracy 0.54634 loss 1.1631476466485877\n",
      "epoch 98 accuracy 0.547 loss 1.15884919825135\n",
      "epoch 99 accuracy 0.54398 loss 1.1685657770353617\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "layers = [\n",
    "    Layer(10, 'sigmoid'),\n",
    "    Layer(10, 'sigmoid'),\n",
    "    OutputLayer(10, 'sigmoid')\n",
    "]\n",
    "nn = NeuralNetwork(layers, 18, losses, accuracies)\n",
    "nn.train(X_train, y_train, 0.05, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5447"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = nn.predict(X_test)\n",
    "nn.accuracy(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x195c91a71c0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(nn.accuracies, nn.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mbLNbXd8JELY",
    "outputId": "bcf76cec-e2a7-4198-b7c5-81282523cb56"
   },
   "outputs": [],
   "source": [
    "'''layers2 = [\n",
    "    Layer(35, 'leakyRelu'),\n",
    "    Layer(20, 'leakyRelu'),\n",
    "    OutputLayer(10, 'leakyRelu')\n",
    "]\n",
    "nn2 = NeuralNetwork(layers, 18)\n",
    "nn2.train(X_train, y_train, 1e-7, 100)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Sup2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
