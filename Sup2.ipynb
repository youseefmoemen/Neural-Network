{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youseefmoemen/Neural-Network/blob/main/Sup2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GON6iRSbG-PX"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv84SdZlPrxd"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-1 * z))\n",
        "def sigmoid_grad(z):\n",
        "  t = sigmoid(z)\n",
        "  return t * (1 - t)\n",
        "def leakyRelu(z):\n",
        "  return np.where(z >= 0, z, z * 0.3)\n",
        "def leakyRelu_grad(z):\n",
        "  return np.where(z >= 0, 1, 0.3)\n",
        "def softmax(z):\n",
        "  e = np.exp(z)\n",
        "  return e / np.sum(e)\n",
        "def softmax_grad(z):\n",
        "    I = np.eye(z.shape)\n",
        "    return np.dot((I - softmax(z)).T, softmax(z))\n",
        "def tanh(z):\n",
        "  return np.tanh(z)\n",
        "def tanh_grad(z):\n",
        "  return 1 - np.power(tanh(z), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8eh2OJgP7IB"
      },
      "outputs": [],
      "source": [
        "Activations = {\n",
        "    'sigmoid': sigmoid,\n",
        "    'leakyRelu': leakyRelu,\n",
        "    'softmax': softmax,\n",
        "    'tanh': tanh\n",
        "}\n",
        "Activations_grad = {\n",
        "    'sigmoid': sigmoid_grad,\n",
        "    'leakyRelu': leakyRelu_grad,\n",
        "    'softmax': softmax_grad,\n",
        "    'tanh': tanh_grad\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "15j6dXKLIWN_"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "id": "1Vx8P1VUHdk0"
      },
      "outputs": [],
      "source": [
        "mnist = fetch_openml('mnist_784', version = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "id": "KVLMhO_MIYzq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "id": "mXY0wY3DIbFX"
      },
      "outputs": [],
      "source": [
        "sss = StratifiedShuffleSplit(n_splits = 1, train_size=10000, test_size=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 450,
      "metadata": {
        "id": "D1VbSFuaIcp5"
      },
      "outputs": [],
      "source": [
        "for train_index, test_index in sss.split(mnist.data, mnist.target):\n",
        "  X_train = mnist.data.iloc[train_index] \n",
        "  y_train = mnist.target[train_index]\n",
        "  X_test = mnist.data.iloc[test_index] \n",
        "  y_test = mnist.target[test_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 451,
      "metadata": {
        "id": "CKFS19L0Ierk"
      },
      "outputs": [],
      "source": [
        "def clip_image(img, clipping_size = 0):\n",
        "  img = img.reshape((28, 28))\n",
        "  img = np.delete(img, range(clipping_size), 0)\n",
        "  img = np.delete(img, range(clipping_size), 1)\n",
        "  return img.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 452,
      "metadata": {
        "id": "75II8JDuIhF3"
      },
      "outputs": [],
      "source": [
        "def momentum(img, step_size, n_steps, clipping_size):\n",
        "  img = img.reshape((28 - clipping_size, 28-clipping_size))\n",
        "  momentums = []\n",
        "  for i in range(n_steps):\n",
        "    x = np.array(list(range(i*step_size, (i+1)*step_size)))\n",
        "    for j in range(n_steps):\n",
        "      pixels = img[j*step_size: (j+1)*step_size, i*step_size: (i+1) * step_size]\n",
        "      y =  np.array(list(range(j*step_size, (j+1)*step_size))).reshape(step_size,1)\n",
        "      area = np.sum(np.sum(pixels))\n",
        "      x_c = np.sum(np.sum(x.T * pixels)) / (area + 1e-10)\n",
        "      y_c = np.sum(np.sum(y * pixels)) / (area + 1e-10)\n",
        "      momentums.append((x_c, y_c))\n",
        "  return momentums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 453,
      "metadata": {
        "id": "_hZcCsCXIimx"
      },
      "outputs": [],
      "source": [
        "def reduction(data = None, n_momentums = 9):\n",
        "  n_steps = math.floor(np.sqrt(n_momentums))\n",
        "  clipping_size = 28 % n_steps\n",
        "  step_size = (28 - clipping_size) // n_steps\n",
        "  data = np.apply_along_axis(clipping_size = clipping_size\n",
        "                      , func1d = clip_image, axis = 1, arr = data)\n",
        "  momentums = np.apply_along_axis(step_size = step_size, n_steps = n_steps,\n",
        "                                  clipping_size= clipping_size,\n",
        "                                  func1d = momentum, axis = 1, arr = data)\n",
        "  return data, momentums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 454,
      "metadata": {
        "id": "XeGU_ZnMIkCS"
      },
      "outputs": [],
      "source": [
        "X_train = reduction(np.array(X_train.copy()), n_momentums = 9)[1].reshape(10000, 18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 406,
      "metadata": {
        "id": "JDuzFFNDBMWj"
      },
      "outputs": [],
      "source": [
        "class Layer():\n",
        "  def __init__(self, n_neurons, activation):\n",
        "    self.n_neurons = n_neurons\n",
        "    self.w = None\n",
        "    self.activation = Activations[activation]\n",
        "    self.activation_grad = Activations_grad[activation]\n",
        "  \n",
        "  def initialize(self, prev):\n",
        "    self.w = np.random.normal(size=(self.n_neurons, prev))\n",
        "\n",
        "  def compute(self, Oi):\n",
        "    Netj = np.dot(Oi, self.w.T)  # W * Oi\n",
        "    Oj = self.activation(Netj)\n",
        "    return Netj, Oj\n",
        "  \n",
        "  def grad(self, delta, w_next, Oi):\n",
        "    Netj = self.compute(Oi)[0]\n",
        "    partial = np.dot(delta, w_next)\n",
        "    delta = np.multiply(partial, self.activation_grad(Netj))\n",
        "    Dw = np.dot(delta.T, Oi)\n",
        "    return Dw, delta\n",
        "\n",
        "  def update(self, learning_rate, Dw):\n",
        "    hold = self.w.shape\n",
        "    self.w  = self.w  -  learning_rate * Dw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 407,
      "metadata": {
        "id": "OMW5bsyJUuDX"
      },
      "outputs": [],
      "source": [
        "class OutputLayer(Layer):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "  \n",
        "  def grad(self, target, Oi):\n",
        "    Netj, Oj = self.compute(Oi)\n",
        "    delta = np.multiply(-1* (1/target.shape[0]) * (target - Oj), self.activation_grad(Netj))\n",
        "    Dw = np.dot(delta.T, Oi)\n",
        "    return Dw, delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 447,
      "metadata": {
        "id": "-v5Lkksr4xb5"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork():\n",
        "  def __init__(self, layers, input_shape):\n",
        "    self.layers = layers\n",
        "    self.O_ALL = None\n",
        "    self.input_shape = input_shape\n",
        "    self.layers[0].initialize(self.input_shape)\n",
        "    for i in range(1, len(self.layers)):\n",
        "      self.layers[i].initialize(self.layers[i-1].n_neurons)\n",
        "  \n",
        "  def predict(self, X):\n",
        "    Oi = X\n",
        "    self.O_ALL = []\n",
        "    self.O_ALL.append(X)\n",
        "    for layer in self.layers:\n",
        "      Oi = layer.compute(Oi)[1]\n",
        "      self.O_ALL.append(Oi)\n",
        "    return Oi\n",
        "  \n",
        "\n",
        "  def loss(self, Oj, y):\n",
        "    E = (2 / y.shape[0]) * np.sum((y - Oj) ** 2)\n",
        "    return E\n",
        "  \n",
        "  def accuracy(self, y_pred, y_true):\n",
        "    return np.sum(np.equal(np.argmax(y_true, axis = 1), np.argmax(y_pred, axis = 1))) / len(y_true)\n",
        "\n",
        "  def train(self, X_train, y_train, learning_rate, epochs, \n",
        "            X_val = None, y_val = None):\n",
        "    history = []\n",
        "    for i in range(epochs):\n",
        "        y_pred = self.predict(X_train)\n",
        "        print(f'iteration {i} accuracy {self.accuracy(y_pred, y_train)}' ,\n",
        "              f'loss {self.loss(y_train, y_pred)}')\n",
        "        for j in reversed(range(len(self.layers))):\n",
        "          if j == len(self.layers) - 1:\n",
        "            Dw, delta = self.layers[j].grad(y_train, self.O_ALL[-2])\n",
        "          else:\n",
        "            Dw, delta = self.layers[j].grad(delta, hold, self.O_ALL[j])\n",
        "          hold = self.layers[j].w.copy()\n",
        "          self.layers[j].update(learning_rate, Dw)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "X_train, y_train = make_moons()"
      ],
      "metadata": {
        "id": "wQKswqnCeclQ"
      },
      "execution_count": 448,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(y_train)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "y_train = onehot_encoder.fit_transform(integer_encoded)"
      ],
      "metadata": {
        "id": "mwsoltj1MKF0"
      },
      "execution_count": 455,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 460,
      "metadata": {
        "id": "mbLNbXd8JELY"
      },
      "outputs": [],
      "source": [
        "layers = [\n",
        "    Layer(100, 'leakyRelu'),\n",
        "    Layer(50, 'leakyRelu'),\n",
        "    Layer(30, 'leakyRelu'),\n",
        "    OutputLayer(10, 'leakyRelu')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 461,
      "metadata": {
        "id": "sbTF7sh0JTI_"
      },
      "outputs": [],
      "source": [
        "nn = NeuralNetwork(layers, 18)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22KaCJ74Q-sz",
        "outputId": "f7f436b2-b00f-4a8e-a9d0-3f397ae48c90"
      },
      "execution_count": 462,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 18) (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkFR5fzXJWmR"
      },
      "outputs": [],
      "source": [
        "nn.train(X_train, y_train, 1e-8, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in nn.layers:\n",
        "  print(i.w.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBdep_b4AMh_",
        "outputId": "fa8d205e-8392-4b20-dccc-2aaaf6281bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 2)\n",
            "(10, 30)\n",
            "(3, 10)\n",
            "(2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D5-C_1w4BpiK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Sup2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}