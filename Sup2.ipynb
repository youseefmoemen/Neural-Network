{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youseefmoemen/Neural-Network/blob/main/Sup2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GON6iRSbG-PX"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tv84SdZlPrxd"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-1 * z))\n",
        "def sigmoid_grad(z):\n",
        "  t = sigmoid(z)\n",
        "  return t * (1 - t)\n",
        "def leakyRelu(z):\n",
        "  return np.where(z >= 0, z, z * 0.3)\n",
        "def leakyRelu_grad(z):\n",
        "  return np.where(z >= 0, 1, 0.3)\n",
        "def tanh(z):\n",
        "  return np.tanh(z)\n",
        "def tanh_grad(z):\n",
        "  return 1 - np.power(tanh(z), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A8eh2OJgP7IB"
      },
      "outputs": [],
      "source": [
        "Activations = {\n",
        "    'sigmoid': sigmoid,\n",
        "    'leakyRelu': leakyRelu,\n",
        "    'tanh': tanh\n",
        "}\n",
        "Activations_grad = {\n",
        "    'sigmoid': sigmoid_grad,\n",
        "    'leakyRelu': leakyRelu_grad,\n",
        "    'tanh': tanh_grad\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "15j6dXKLIWN_"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1Vx8P1VUHdk0"
      },
      "outputs": [],
      "source": [
        "mnist = fetch_openml('mnist_784', version = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KVLMhO_MIYzq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mXY0wY3DIbFX"
      },
      "outputs": [],
      "source": [
        "sss = StratifiedShuffleSplit(n_splits = 1, train_size=50000, test_size=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D1VbSFuaIcp5"
      },
      "outputs": [],
      "source": [
        "for train_index, test_index in sss.split(mnist.data, mnist.target):\n",
        "  X_train = mnist.data.iloc[train_index] \n",
        "  y_train = mnist.target[train_index]\n",
        "  X_test = mnist.data.iloc[test_index] \n",
        "  y_test = mnist.target[test_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CKFS19L0Ierk"
      },
      "outputs": [],
      "source": [
        "def clip_image(img, clipping_size = 0):\n",
        "  img = img.reshape((28, 28))\n",
        "  img = np.delete(img, range(clipping_size), 0)\n",
        "  img = np.delete(img, range(clipping_size), 1)\n",
        "  return img.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "75II8JDuIhF3"
      },
      "outputs": [],
      "source": [
        "def momentum(img, step_size, n_steps, clipping_size):\n",
        "  img = img.reshape((28 - clipping_size, 28-clipping_size))\n",
        "  momentums = []\n",
        "  for i in range(n_steps):\n",
        "    x = np.array(list(range(i*step_size, (i+1)*step_size)))\n",
        "    for j in range(n_steps):\n",
        "      pixels = img[j*step_size: (j+1)*step_size, i*step_size: (i+1) * step_size]\n",
        "      y =  np.array(list(range(j*step_size, (j+1)*step_size))).reshape(step_size,1)\n",
        "      area = np.sum(np.sum(pixels))\n",
        "      x_c = np.sum(np.sum(x.T * pixels)) / (area + 1e-10)\n",
        "      y_c = np.sum(np.sum(y * pixels)) / (area + 1e-10)\n",
        "      momentums.append((x_c, y_c))\n",
        "  return momentums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_hZcCsCXIimx"
      },
      "outputs": [],
      "source": [
        "def reduction(data = None, n_momentums = 9):\n",
        "  n_steps = math.floor(np.sqrt(n_momentums))\n",
        "  clipping_size = 28 % n_steps\n",
        "  step_size = (28 - clipping_size) // n_steps\n",
        "  data = np.apply_along_axis(clipping_size = clipping_size\n",
        "                      , func1d = clip_image, axis = 1, arr = data)\n",
        "  momentums = np.apply_along_axis(step_size = step_size, n_steps = n_steps,\n",
        "                                  clipping_size= clipping_size,\n",
        "                                  func1d = momentum, axis = 1, arr = data)\n",
        "  return data, momentums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XeGU_ZnMIkCS"
      },
      "outputs": [],
      "source": [
        "X_train = reduction(np.array(X_train.copy()), n_momentums = 9)[1].reshape(50000, 18)\n",
        "y_train2 = np.zeros(shape=(y_train.shape[0], 10))\n",
        "for index, instance in enumerate(y_train):\n",
        "  y_train2[index][int(instance)] = 1\n",
        "y_train = y_train2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JDuzFFNDBMWj"
      },
      "outputs": [],
      "source": [
        "class Layer():\n",
        "  def __init__(self, n_neurons, activation):\n",
        "    self.n_neurons = n_neurons\n",
        "    self.w = None\n",
        "    self.activation = Activations[activation]\n",
        "    self.activation_grad = Activations_grad[activation]\n",
        "  \n",
        "  def initialize(self, prev):\n",
        "    self.w = np.random.normal(size=(self.n_neurons, prev))\n",
        "\n",
        "  def compute(self, Oi):\n",
        "    Netj = np.dot(Oi, self.w.T)  \n",
        "    Oj = self.activation(Netj)\n",
        "    return Netj, Oj\n",
        "  \n",
        "  def grad(self, delta, w_next, Oi):\n",
        "    Netj = self.compute(Oi)[0]\n",
        "    partial = np.dot(delta, w_next)\n",
        "    delta = np.multiply(partial, self.activation_grad(Netj))\n",
        "    Dw = np.dot(delta.T, Oi)\n",
        "    return Dw, delta\n",
        "\n",
        "  def update(self, learning_rate, Dw):\n",
        "    hold = self.w.shape\n",
        "    self.w  = self.w  -  learning_rate * Dw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OMW5bsyJUuDX"
      },
      "outputs": [],
      "source": [
        "class OutputLayer(Layer):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "  \n",
        "  def grad(self, target, Oi):\n",
        "    Netj, Oj = self.compute(Oi)\n",
        "    delta = np.multiply(-1* (1/target.shape[0]) * (target - Oj), self.activation_grad(Netj))\n",
        "    Dw = np.dot(delta.T, Oi)\n",
        "    return Dw, delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-v5Lkksr4xb5"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork():\n",
        "  def __init__(self, layers, input_shape):\n",
        "    self.layers = layers\n",
        "    self.O_ALL = None\n",
        "    self.input_shape = input_shape\n",
        "    self.layers[0].initialize(self.input_shape)\n",
        "    for i in range(1, len(self.layers)):\n",
        "      self.layers[i].initialize(self.layers[i-1].n_neurons)\n",
        "  \n",
        "  def predict(self, X):\n",
        "    Oi = X\n",
        "    self.O_ALL = []\n",
        "    self.O_ALL.append(X)\n",
        "    for layer in self.layers:\n",
        "      Oi = layer.compute(Oi)[1]\n",
        "      self.O_ALL.append(Oi)\n",
        "    return Oi\n",
        "  \n",
        "\n",
        "  def loss(self, Oj, y):\n",
        "    E = (2 / y.shape[0]) * np.sum((y - Oj) ** 2)\n",
        "    return E\n",
        "  \n",
        "  def arg(self, y):\n",
        "    predictions = np.zeros((y.shape[0], 1))\n",
        "    for index, instance in enumerate(y):\n",
        "      idx = 0\n",
        "      for i in range(1, 10):\n",
        "        if instance[i] > instance[idx]:\n",
        "          idx = i\n",
        "      predictions[index] = idx\n",
        "    return predictions\n",
        "\n",
        "  def accuracy(self, y_pred, y_true):\n",
        "    return np.sum(np.equal(self.arg(y_true), self.arg(y_pred))) / len(y_true)\n",
        "\n",
        "  def train(self, X_train, y_train, learning_rate, epochs, \n",
        "            X_val = None, y_val = None):\n",
        "    for i in range(epochs):\n",
        "        y_pred = self.predict(X_train)\n",
        "        print(f'epoch {i} accuracy {self.accuracy(y_pred, y_train)}' ,\n",
        "              f'loss {self.loss(y_train, y_pred)}')\n",
        "        for index, instance in enumerate(X_train):\n",
        "          self.predict(instance.reshape(1, -1))\n",
        "          for j in reversed(range(len(self.layers))):\n",
        "            if j == len(self.layers) - 1:\n",
        "              Dw, delta = self.layers[j].grad(y_train[index], self.O_ALL[-2])\n",
        "            else:\n",
        "              Dw, delta = self.layers[j].grad(delta, hold, self.O_ALL[j])\n",
        "            hold = self.layers[j].w.copy()\n",
        "            self.layers[j].update(learning_rate, Dw)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers2 = [\n",
        "    Layer(10, 'sigmoid'),\n",
        "    Layer(10, 'sigmoid'),\n",
        "    OutputLayer(10, 'sigmoid')\n",
        "]\n",
        "nn2 = NeuralNetwork(layers2, 18)\n",
        "nn2.train(X_train, y_train, 1e-7, 10)"
      ],
      "metadata": {
        "id": "D5-C_1w4BpiK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e53297-9ebc-456a-bd73-8f4c9a39d8bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 accuracy 0.10386 loss 8.337567507330395\n",
            "epoch 1 accuracy 0.10384 loss 8.337168699879777\n",
            "epoch 2 accuracy 0.10384 loss 8.336769844062443\n",
            "epoch 3 accuracy 0.10382 loss 8.336370939832715\n",
            "epoch 4 accuracy 0.1038 loss 8.335971987144656\n",
            "epoch 5 accuracy 0.10378 loss 8.335572985952203\n",
            "epoch 6 accuracy 0.10378 loss 8.335173936209259\n",
            "epoch 7 accuracy 0.10378 loss 8.33477483786942\n",
            "epoch 8 accuracy 0.10378 loss 8.33437569088628\n",
            "epoch 9 accuracy 0.10378 loss 8.333976495213195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbLNbXd8JELY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcf76cec-e2a7-4198-b7c5-81282523cb56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 accuracy 0.12258 loss 2541310.7189342887\n",
            "epoch 1 accuracy 0.19718 loss 13291.477733469028\n",
            "epoch 2 accuracy 0.19764 loss 7646.9010442815415\n",
            "epoch 3 accuracy 0.17996 loss 5468.70352353967\n",
            "epoch 4 accuracy 0.16286 loss 4278.453625815075\n",
            "epoch 5 accuracy 0.15392 loss 3504.210564583275\n",
            "epoch 6 accuracy 0.1505 loss 2952.695372237765\n",
            "epoch 7 accuracy 0.14722 loss 2566.533241567428\n",
            "epoch 8 accuracy 0.14506 loss 2282.1694541575603\n",
            "epoch 9 accuracy 0.14334 loss 2061.9030510780094\n",
            "epoch 10 accuracy 0.1414 loss 1882.6737368871575\n",
            "epoch 11 accuracy 0.14136 loss 1732.3372912753503\n",
            "epoch 12 accuracy 0.14134 loss 1603.5869476023477\n",
            "epoch 13 accuracy 0.14078 loss 1491.623546606244\n",
            "epoch 14 accuracy 0.1404 loss 1393.3294479903834\n",
            "epoch 15 accuracy 0.13934 loss 1306.3586863837047\n",
            "epoch 16 accuracy 0.139 loss 1228.988984722693\n",
            "epoch 17 accuracy 0.139 loss 1159.9009384716198\n",
            "epoch 18 accuracy 0.1389 loss 1097.9150199950768\n",
            "epoch 19 accuracy 0.13858 loss 1041.959784938112\n",
            "epoch 20 accuracy 0.13824 loss 991.2565067369179\n",
            "epoch 21 accuracy 0.13836 loss 945.1096148409306\n",
            "epoch 22 accuracy 0.13852 loss 902.896814527714\n",
            "epoch 23 accuracy 0.13926 loss 864.1699818484408\n",
            "epoch 24 accuracy 0.13886 loss 828.5077867731181\n",
            "epoch 25 accuracy 0.13822 loss 795.46494827716\n",
            "epoch 26 accuracy 0.13802 loss 764.6957898531756\n",
            "epoch 27 accuracy 0.13758 loss 736.0005890417154\n",
            "epoch 28 accuracy 0.13762 loss 709.305294847482\n",
            "epoch 29 accuracy 0.1371 loss 684.46210717071\n",
            "epoch 30 accuracy 0.13672 loss 661.3337751303777\n",
            "epoch 31 accuracy 0.13626 loss 639.7586418656222\n",
            "epoch 32 accuracy 0.13552 loss 619.6061732774863\n",
            "epoch 33 accuracy 0.13484 loss 600.7321221263942\n",
            "epoch 34 accuracy 0.13416 loss 583.0377940854081\n",
            "epoch 35 accuracy 0.13414 loss 566.4164847966114\n",
            "epoch 36 accuracy 0.13382 loss 550.7604859721737\n",
            "epoch 37 accuracy 0.13336 loss 535.9907289706026\n",
            "epoch 38 accuracy 0.13302 loss 522.0370701924512\n",
            "epoch 39 accuracy 0.1333 loss 508.82464745477694\n",
            "epoch 40 accuracy 0.13318 loss 496.307804265216\n",
            "epoch 41 accuracy 0.13292 loss 484.4181932554337\n",
            "epoch 42 accuracy 0.13266 loss 473.100344044719\n",
            "epoch 43 accuracy 0.1326 loss 462.3161393154652\n",
            "epoch 44 accuracy 0.13216 loss 452.0327733086386\n",
            "epoch 45 accuracy 0.13174 loss 442.2037199586248\n",
            "epoch 46 accuracy 0.13146 loss 432.8080740029418\n",
            "epoch 47 accuracy 0.13094 loss 423.80990052780453\n",
            "epoch 48 accuracy 0.13044 loss 415.18231225390184\n",
            "epoch 49 accuracy 0.13002 loss 406.8922143056064\n",
            "epoch 50 accuracy 0.12964 loss 398.93246144418094\n",
            "epoch 51 accuracy 0.12936 loss 391.28405697690386\n",
            "epoch 52 accuracy 0.129 loss 383.9237974367297\n",
            "epoch 53 accuracy 0.12874 loss 376.84035732608726\n",
            "epoch 54 accuracy 0.12834 loss 370.01205582847723\n",
            "epoch 55 accuracy 0.12804 loss 363.42388977553014\n",
            "epoch 56 accuracy 0.12776 loss 357.0634950099934\n",
            "epoch 57 accuracy 0.12736 loss 350.91586796825584\n",
            "epoch 58 accuracy 0.12708 loss 344.96909211738716\n",
            "epoch 59 accuracy 0.12668 loss 339.2177907097079\n",
            "epoch 60 accuracy 0.12612 loss 333.6465916708805\n",
            "epoch 61 accuracy 0.1256 loss 328.2507705360905\n",
            "epoch 62 accuracy 0.12534 loss 323.017854257653\n",
            "epoch 63 accuracy 0.12506 loss 317.941840162211\n",
            "epoch 64 accuracy 0.12464 loss 313.0108712140167\n",
            "epoch 65 accuracy 0.1244 loss 308.2184954934596\n",
            "epoch 66 accuracy 0.12384 loss 303.5700015957152\n",
            "epoch 67 accuracy 0.12374 loss 299.04191725337245\n",
            "epoch 68 accuracy 0.1234 loss 294.63158596049004\n",
            "epoch 69 accuracy 0.12306 loss 290.3349600346499\n",
            "epoch 70 accuracy 0.12292 loss 286.14821001691695\n",
            "epoch 71 accuracy 0.12266 loss 282.07067702023346\n",
            "epoch 72 accuracy 0.12204 loss 278.0990053041627\n",
            "epoch 73 accuracy 0.12162 loss 274.22387334498063\n",
            "epoch 74 accuracy 0.12094 loss 270.44394467519055\n",
            "epoch 75 accuracy 0.12054 loss 266.75572876712647\n",
            "epoch 76 accuracy 0.1197 loss 263.16068541162883\n",
            "epoch 77 accuracy 0.1192 loss 259.65717258932347\n",
            "epoch 78 accuracy 0.11882 loss 256.2319022145593\n",
            "epoch 79 accuracy 0.11838 loss 252.89073048116398\n",
            "epoch 80 accuracy 0.11796 loss 249.62625329590975\n",
            "epoch 81 accuracy 0.11726 loss 246.43965426989215\n",
            "epoch 82 accuracy 0.1167 loss 243.3282712877209\n",
            "epoch 83 accuracy 0.116 loss 240.287563548162\n",
            "epoch 84 accuracy 0.11534 loss 237.31769408591362\n",
            "epoch 85 accuracy 0.11442 loss 234.41741497083942\n",
            "epoch 86 accuracy 0.11368 loss 231.58029365999957\n",
            "epoch 87 accuracy 0.11314 loss 228.80139303883428\n",
            "epoch 88 accuracy 0.11304 loss 226.08313375708488\n",
            "epoch 89 accuracy 0.11288 loss 223.42344818274873\n",
            "epoch 90 accuracy 0.11224 loss 220.82296406889765\n",
            "epoch 91 accuracy 0.11182 loss 218.27905774633692\n",
            "epoch 92 accuracy 0.11184 loss 215.7921767823012\n",
            "epoch 93 accuracy 0.11184 loss 213.35811303121434\n",
            "epoch 94 accuracy 0.1116 loss 210.9751605337392\n",
            "epoch 95 accuracy 0.1109 loss 208.64110948916016\n",
            "epoch 96 accuracy 0.11062 loss 206.35555630135653\n",
            "epoch 97 accuracy 0.11038 loss 204.1158157890627\n",
            "epoch 98 accuracy 0.1102 loss 201.9213559173063\n",
            "epoch 99 accuracy 0.10992 loss 199.77211281697706\n",
            "epoch 100 accuracy 0.10974 loss 197.66574533924455\n",
            "epoch 101 accuracy 0.10966 loss 195.6038798405667\n",
            "epoch 102 accuracy 0.1094 loss 193.5823225749998\n",
            "epoch 103 accuracy 0.1094 loss 191.59782163323024\n",
            "epoch 104 accuracy 0.10926 loss 189.65165676427497\n",
            "epoch 105 accuracy 0.10922 loss 187.73940531415147\n",
            "epoch 106 accuracy 0.10868 loss 185.8651877904336\n",
            "epoch 107 accuracy 0.10874 loss 184.02488621383338\n",
            "epoch 108 accuracy 0.10848 loss 182.21910376776265\n",
            "epoch 109 accuracy 0.10818 loss 180.44818444163442\n",
            "epoch 110 accuracy 0.10794 loss 178.70827182389402\n",
            "epoch 111 accuracy 0.10802 loss 176.99869313427416\n",
            "epoch 112 accuracy 0.10786 loss 175.3202818660711\n",
            "epoch 113 accuracy 0.10754 loss 173.6712069650259\n",
            "epoch 114 accuracy 0.1074 loss 172.05002960642625\n",
            "epoch 115 accuracy 0.10724 loss 170.46090783465047\n",
            "epoch 116 accuracy 0.10726 loss 168.8978656603883\n",
            "epoch 117 accuracy 0.10692 loss 167.35962977921878\n",
            "epoch 118 accuracy 0.10678 loss 165.84728494988585\n",
            "epoch 119 accuracy 0.10646 loss 164.35920926553598\n",
            "epoch 120 accuracy 0.10606 loss 162.89354238690376\n",
            "epoch 121 accuracy 0.10566 loss 161.45207936630234\n",
            "epoch 122 accuracy 0.10522 loss 160.03329031482795\n",
            "epoch 123 accuracy 0.10518 loss 158.6365934323603\n",
            "epoch 124 accuracy 0.10466 loss 157.26156138985075\n",
            "epoch 125 accuracy 0.10398 loss 155.90889245185377\n",
            "epoch 126 accuracy 0.10368 loss 154.5753956598127\n",
            "epoch 127 accuracy 0.1033 loss 153.26177943098244\n",
            "epoch 128 accuracy 0.103 loss 151.96946705412282\n",
            "epoch 129 accuracy 0.10264 loss 150.6950401032878\n",
            "epoch 130 accuracy 0.10244 loss 149.4377308827651\n",
            "epoch 131 accuracy 0.10194 loss 148.19554132813494\n",
            "epoch 132 accuracy 0.10166 loss 146.97316262935354\n",
            "epoch 133 accuracy 0.10106 loss 145.76648098132588\n",
            "epoch 134 accuracy 0.10084 loss 144.57690670014446\n",
            "epoch 135 accuracy 0.10058 loss 143.4046804793672\n",
            "epoch 136 accuracy 0.10058 loss 142.24815641976187\n",
            "epoch 137 accuracy 0.10014 loss 141.10544985129275\n",
            "epoch 138 accuracy 0.09964 loss 139.97875092504768\n",
            "epoch 139 accuracy 0.09956 loss 138.87124452039242\n",
            "epoch 140 accuracy 0.0993 loss 137.7815543004497\n",
            "epoch 141 accuracy 0.09912 loss 136.70880448302682\n",
            "epoch 142 accuracy 0.09882 loss 135.6553965529037\n",
            "epoch 143 accuracy 0.0985 loss 134.61956622442108\n",
            "epoch 144 accuracy 0.09848 loss 133.598846476048\n",
            "epoch 145 accuracy 0.09874 loss 132.5943679373194\n",
            "epoch 146 accuracy 0.09882 loss 131.6048972693168\n",
            "epoch 147 accuracy 0.09882 loss 130.6318001881702\n",
            "epoch 148 accuracy 0.09856 loss 129.67475769790616\n",
            "epoch 149 accuracy 0.09858 loss 128.7299828431819\n",
            "epoch 150 accuracy 0.09844 loss 127.7980406539859\n",
            "epoch 151 accuracy 0.0986 loss 126.87963482000796\n",
            "epoch 152 accuracy 0.09868 loss 125.9731242399259\n",
            "epoch 153 accuracy 0.0985 loss 125.07924332905026\n",
            "epoch 154 accuracy 0.09858 loss 124.1978403909816\n",
            "epoch 155 accuracy 0.09856 loss 123.32853776274254\n",
            "epoch 156 accuracy 0.09864 loss 122.47158724919356\n",
            "epoch 157 accuracy 0.09872 loss 121.62513832227758\n",
            "epoch 158 accuracy 0.09886 loss 120.79035657527142\n",
            "epoch 159 accuracy 0.09882 loss 119.96648634597672\n",
            "epoch 160 accuracy 0.09884 loss 119.15350119665973\n",
            "epoch 161 accuracy 0.09896 loss 118.35078504370578\n",
            "epoch 162 accuracy 0.09916 loss 117.55794521056558\n",
            "epoch 163 accuracy 0.09918 loss 116.77426235580516\n",
            "epoch 164 accuracy 0.09912 loss 115.99971977391839\n",
            "epoch 165 accuracy 0.09922 loss 115.23443407109662\n",
            "epoch 166 accuracy 0.09938 loss 114.47880583410256\n",
            "epoch 167 accuracy 0.09948 loss 113.73260385110991\n",
            "epoch 168 accuracy 0.0995 loss 112.99545111617458\n",
            "epoch 169 accuracy 0.0995 loss 112.26706680177875\n",
            "epoch 170 accuracy 0.09948 loss 111.5480684086631\n",
            "epoch 171 accuracy 0.0997 loss 110.83717022982142\n",
            "epoch 172 accuracy 0.09964 loss 110.13459036185813\n",
            "epoch 173 accuracy 0.09982 loss 109.44036490177636\n",
            "epoch 174 accuracy 0.09978 loss 108.75361877865517\n",
            "epoch 175 accuracy 0.09978 loss 108.07444889736492\n",
            "epoch 176 accuracy 0.09994 loss 107.40234237429675\n",
            "epoch 177 accuracy 0.10006 loss 106.7380181335135\n",
            "epoch 178 accuracy 0.10022 loss 106.08157293235735\n",
            "epoch 179 accuracy 0.10048 loss 105.43232808443022\n",
            "epoch 180 accuracy 0.10044 loss 104.79036131562718\n",
            "epoch 181 accuracy 0.10052 loss 104.15616252853128\n",
            "epoch 182 accuracy 0.10064 loss 103.52901533516037\n",
            "epoch 183 accuracy 0.101 loss 102.90948520196606\n",
            "epoch 184 accuracy 0.10114 loss 102.29778241415383\n",
            "epoch 185 accuracy 0.10118 loss 101.69296415718748\n",
            "epoch 186 accuracy 0.10124 loss 101.09527866700722\n",
            "epoch 187 accuracy 0.10152 loss 100.50439769698977\n",
            "epoch 188 accuracy 0.10174 loss 99.9200518889182\n",
            "epoch 189 accuracy 0.10186 loss 99.34167001992206\n",
            "epoch 190 accuracy 0.10196 loss 98.76972442766142\n",
            "epoch 191 accuracy 0.10216 loss 98.20397381043539\n",
            "epoch 192 accuracy 0.10228 loss 97.64439203328283\n",
            "epoch 193 accuracy 0.1022 loss 97.09107479609442\n",
            "epoch 194 accuracy 0.10244 loss 96.5437149530072\n",
            "epoch 195 accuracy 0.1027 loss 96.00186763207691\n",
            "epoch 196 accuracy 0.1027 loss 95.4653448760626\n",
            "epoch 197 accuracy 0.1027 loss 94.93461184662269\n",
            "epoch 198 accuracy 0.10288 loss 94.40904439517169\n",
            "epoch 199 accuracy 0.103 loss 93.8896166283608\n",
            "epoch 200 accuracy 0.10314 loss 93.37559935915735\n",
            "epoch 201 accuracy 0.1031 loss 92.86708603537942\n",
            "epoch 202 accuracy 0.1033 loss 92.36369904126217\n",
            "epoch 203 accuracy 0.10336 loss 91.86581654988738\n",
            "epoch 204 accuracy 0.10358 loss 91.37224217636184\n",
            "epoch 205 accuracy 0.10366 loss 90.88365849657605\n",
            "epoch 206 accuracy 0.10376 loss 90.40008763925071\n",
            "epoch 207 accuracy 0.10382 loss 89.92092763647318\n",
            "epoch 208 accuracy 0.10382 loss 89.4463558938718\n",
            "epoch 209 accuracy 0.10382 loss 88.97640118094776\n",
            "epoch 210 accuracy 0.10408 loss 88.51128866766003\n",
            "epoch 211 accuracy 0.10396 loss 88.05047716961624\n",
            "epoch 212 accuracy 0.10394 loss 87.59407347255089\n",
            "epoch 213 accuracy 0.10406 loss 87.14194750421886\n",
            "epoch 214 accuracy 0.10424 loss 86.69406909235789\n",
            "epoch 215 accuracy 0.10434 loss 86.25044115809315\n",
            "epoch 216 accuracy 0.10446 loss 85.81058353514851\n",
            "epoch 217 accuracy 0.10462 loss 85.37513725015609\n",
            "epoch 218 accuracy 0.10454 loss 84.94347631860207\n",
            "epoch 219 accuracy 0.10482 loss 84.51566045019668\n",
            "epoch 220 accuracy 0.1048 loss 84.09176767593625\n",
            "epoch 221 accuracy 0.10502 loss 83.67176755225354\n",
            "epoch 222 accuracy 0.10498 loss 83.25579217858515\n",
            "epoch 223 accuracy 0.10518 loss 82.84330860114473\n",
            "epoch 224 accuracy 0.10526 loss 82.43407935329788\n",
            "epoch 225 accuracy 0.10548 loss 82.0287939482321\n",
            "epoch 226 accuracy 0.10568 loss 81.62672377757059\n",
            "epoch 227 accuracy 0.10596 loss 81.22815115488696\n",
            "epoch 228 accuracy 0.10624 loss 80.83290407212874\n",
            "epoch 229 accuracy 0.10628 loss 80.44126303683208\n",
            "epoch 230 accuracy 0.10634 loss 80.05305437829568\n",
            "epoch 231 accuracy 0.10668 loss 79.66791028539986\n",
            "epoch 232 accuracy 0.10708 loss 79.28591924938712\n",
            "epoch 233 accuracy 0.10734 loss 78.90749871906345\n",
            "epoch 234 accuracy 0.10746 loss 78.53221123972948\n",
            "epoch 235 accuracy 0.10742 loss 78.1598377240543\n",
            "epoch 236 accuracy 0.10742 loss 77.79039342067654\n",
            "epoch 237 accuracy 0.1075 loss 77.42366206939572\n",
            "epoch 238 accuracy 0.10764 loss 77.05959443611182\n",
            "epoch 239 accuracy 0.1078 loss 76.69853249107584\n",
            "epoch 240 accuracy 0.10806 loss 76.34055871020524\n",
            "epoch 241 accuracy 0.10814 loss 75.98532911661059\n",
            "epoch 242 accuracy 0.10832 loss 75.63285694404348\n",
            "epoch 243 accuracy 0.1084 loss 75.28360619342975\n",
            "epoch 244 accuracy 0.10838 loss 74.93739939244358\n",
            "epoch 245 accuracy 0.1085 loss 74.59405473214939\n",
            "epoch 246 accuracy 0.1086 loss 74.25352135022474\n",
            "epoch 247 accuracy 0.10854 loss 73.91547949622412\n",
            "epoch 248 accuracy 0.1086 loss 73.58023529696071\n",
            "epoch 249 accuracy 0.10868 loss 73.24773951863706\n",
            "epoch 250 accuracy 0.10888 loss 72.91751208477143\n",
            "epoch 251 accuracy 0.10896 loss 72.59006814927581\n",
            "epoch 252 accuracy 0.10906 loss 72.26536809013936\n",
            "epoch 253 accuracy 0.10914 loss 71.94282501482742\n",
            "epoch 254 accuracy 0.1093 loss 71.62267401377521\n",
            "epoch 255 accuracy 0.10946 loss 71.30576383368982\n",
            "epoch 256 accuracy 0.10956 loss 70.99148925632659\n",
            "epoch 257 accuracy 0.1095 loss 70.67959369302275\n",
            "epoch 258 accuracy 0.10954 loss 70.37017129901675\n",
            "epoch 259 accuracy 0.10962 loss 70.0631827818321\n",
            "epoch 260 accuracy 0.10982 loss 69.75862069148984\n",
            "epoch 261 accuracy 0.1099 loss 69.45616921688291\n",
            "epoch 262 accuracy 0.10992 loss 69.15610449662724\n",
            "epoch 263 accuracy 0.11014 loss 68.85821028046561\n",
            "epoch 264 accuracy 0.11034 loss 68.56239929708128\n",
            "epoch 265 accuracy 0.11042 loss 68.26891634159828\n",
            "epoch 266 accuracy 0.11056 loss 67.97741102948694\n",
            "epoch 267 accuracy 0.11066 loss 67.68838768039575\n"
          ]
        }
      ],
      "source": [
        "layers = [\n",
        "    Layer(35, 'leakyRelu'),\n",
        "    Layer(20, 'leakyRelu'),\n",
        "    OutputLayer(10, 'leakyRelu')\n",
        "]\n",
        "nn = NeuralNetwork(layers, 18)\n",
        "nn.train(X_train, y_train, 1e-7, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "#history"
      ],
      "metadata": {
        "id": "3cUY-qa7-CvS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Sup2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}